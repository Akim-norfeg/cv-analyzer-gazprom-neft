import streamlit as st
import pandas as pd
import logging
import os
import psycopg2
import torch
import datetime
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import mplcyberpunk

from utils.cv_reader import read_resume_from_file
from utils.github_reader import extract_github_links_from_text
from utils.constants import (
    competency_list,
    profession_matrix,
    profession_names,
    recommendations,
    THRESHOLD)
from utils.email import (
    get_gmail_service,
    send_email_custom,
    send_bulk_mail,
    send_confirmation_email,
)
from utils.cached_app_utils import (
    preprocess_cached,
    collect_github_text_cached,
    load_model_safe,
    validate_candidate_form,
    save_application_to_db,
)

import psycopg2
import psycopg2.errors

# ‚îÄ‚îÄ‚îÄ –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    filename="logs/errors.log",
    level=logging.ERROR,
    format="%(asctime)s ‚Äî %(levelname)s ‚Äî %(message)s"
)
plt.style.use('cyberpunk')
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ –ø–æ –º–∞—Ç—Ä–∏—Ü–µ –ê–ª—å—è–Ω—Å–∞ –ò–ò",
    page_icon="others/logo.png",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ‚îÄ‚îÄ‚îÄ –í—ã–±–æ—Ä —Ä–æ–ª–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if "role" not in st.session_state:
    st.session_state.role = None

if st.session_state.role is None:
    st.title("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ CV-Analyzer")
    st.write("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ, –∫—Ç–æ –≤—ã:")
    choice = st.radio("", ["–ö–∞–Ω–¥–∏–¥–∞—Ç", "HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç"])
    if st.button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å"):
        st.session_state.role = "candidate" if choice == "–ö–∞–Ω–¥–∏–¥–∞—Ç" else "hr"
    st.stop()

# ‚îÄ‚îÄ‚îÄ –ü–æ—Ç–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if st.session_state.role == "candidate":
    st.title("–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ –ø–æ –º–∞—Ç—Ä–∏—Ü–µ –ê–ª—å—è–Ω—Å–∞ –ò–ò")

    if "form_filled" not in st.session_state:
        st.session_state.form_filled = False

    # –®–∞–≥ 1: —Ñ–æ—Ä–º–∞
    if not st.session_state.form_filled:
        st.markdown("## –®–∞–≥ 1. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞")
        with st.form("candidate_form"):
            surname          = st.text_input("–§–∞–º–∏–ª–∏—è")
            name             = st.text_input("–ò–º—è")
            patronymic       = st.text_input("–û—Ç—á–µ—Å—Ç–≤–æ")
            email            = st.text_input("Email")
            professions      = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ –¥–≤—É—Ö –≤–∞–∫–∞–Ω—Å–∏–π, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥–∞—Ç—å—Å—è",
                options=profession_names,
                help="–ú–∞–∫—Å–∏–º—É–º 2",
                max_selections=2
            )
            st.markdown("**–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π:**")
            prof_desc = {
                "–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö":           "–†–∞–±–æ—Ç–∞–µ—Ç —Å –¥–∞–Ω–Ω—ã–º–∏, —Å—Ç—Ä–æ–∏—Ç ML-—Ä–µ—à–µ–Ω–∏—è, –≤–µ–¥—ë—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.",
                "–ú–µ–Ω–µ–¥–∂–µ—Ä –≤ –ò–ò":             "–†—É–∫–æ–≤–æ–¥–∏—Ç –ø—Ä–æ–µ–∫—Ç–æ–º, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å—Ä–æ–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã.",
                "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤ –ò–ò": "–°–æ–±–∏—Ä–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –≥–æ—Ç–æ–≤–∏—Ç –¢–ó, —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–µ—à–µ–Ω–∏—è.",
                "–ò–Ω–∂–µ–Ω–µ—Ä –¥–∞–Ω–Ω—ã—Ö":            "–°–æ–±–∏—Ä–∞–µ—Ç, –æ—á–∏—â–∞–µ—Ç –∏ –ø–µ—Ä–µ–¥–∞—ë—Ç –¥–∞–Ω–Ω—ã–µ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞–π–ø–ª–∞–π–Ω—ã."
            }
            for prof in profession_names:
                st.markdown(f"- **{prof}**: {prof_desc[prof]}")
            telegram_handle = st.text_input("Telegram-–Ω–∏–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, @username)")
            phone           = st.text_input("–¢–µ–ª–µ—Ñ–æ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ +7XXXXXXXXXX")
            consent         = st.checkbox(
                "–Ø –¥–∞—é —Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –º–æ–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–º–∫–∞—Ö –æ—Ç–±–æ—Ä–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤. "
                "–ú–æ–∏ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–≤—è–∑–∏ –∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –ø–æ –º–æ–µ–º—É —Ä–µ–∑—é–º–µ."
            )
            submit = st.form_submit_button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∫ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–∑—é–º–µ")

        if submit:
            error = validate_candidate_form(
                surname, name, email, professions, telegram_handle, phone, consent
            )
            if error:
                st.error(error)
                logging.warning(f"Candidate form validation failed: {error}")
            else:
                st.session_state.update({
                    "surname": surname,
                    "name": name,
                    "patronymic": patronymic,
                    "email": email,
                    "selected_professions": professions,
                    "telegram_handle": telegram_handle,
                    "phone": phone,
                    "consent": consent,
                    "form_filled": True,
                    "form_submitted_at": datetime.datetime.now(datetime.timezone.utc)
                })
                st.info("‚úÖ –§–æ—Ä–º–∞ –ø—Ä–∏–Ω—è—Ç–∞, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–∑—é–º–µ‚Ä¶")

        if not st.session_state.form_filled:
            st.stop()

    # –®–∞–≥ 2: –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ –∏ –∞–Ω–∞–ª–∏–∑
    st.markdown("## –®–∞–≥ 2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ")
    uploaded_file = st.file_uploader(
        "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ (PDF, DOCX, TXT), –Ω–µ –±–æ–ª–µ–µ 10 MB",
        type=["pdf", "docx", "txt"]
    )

    if uploaded_file:
        if uploaded_file.size > 10 * 1024 * 1024:
            st.error("‚ùå –§–∞–π–ª –±–æ–ª—å—à–µ 10 MB, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–µ–Ω—å—à–∏–π.")
            st.stop()

        tmp_dir = "temp"
        os.makedirs(tmp_dir, exist_ok=True)
        tmp_path = os.path.join(tmp_dir, uploaded_file.name)
        with open(tmp_path, "wb") as f:
            f.write(uploaded_file.read())

        try:
            with st.spinner("‚è≥ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞..."):
                raw = read_resume_from_file(tmp_path)
                if not raw or not raw.strip():
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ.")
                    st.stop()

                links = extract_github_links_from_text(raw)
                st.session_state.gh_links = links
                gh_text = ""
                if links:
                    st.markdown("üîó **GitHub-—Å—Å—ã–ª–∫–∏:**")
                    for link in links:
                        st.markdown(f"- {link}")
                        try:
                            gh_text += " " + collect_github_text_cached(link)
                        except Exception:
                            st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ GitHub-—Ç–µ–∫—Å—Ç–∞ {link}")
                combined = raw + " " + gh_text
                text = preprocess_cached(combined)

            with st.spinner("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ..."):
                tokenizer, model = load_model_safe()
                inputs = tokenizer(text, return_tensors="pt", padding=True,
                                   truncation=True, max_length=512)
                with torch.no_grad():
                    logits = model(**inputs).logits
                probs = torch.sigmoid(logits).squeeze().cpu().numpy()
                preds = (probs > THRESHOLD).astype(int)

                st.session_state.prob_vector = probs
                st.session_state.pred_vector = preds
                st.session_state.uploaded_file = uploaded_file

            tab = st.tabs(["–û—Ü–µ–Ω–∫–∞ –≥—Ä–µ–π–¥–æ–≤"])[0]
            with tab:
                st.subheader("–û—Ü–µ–Ω–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å –≤–ª–∞–¥–µ–Ω–∏—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏ (0‚Äì3):")
                user_grades = []
                c1, c2 = st.columns(2)
                for i, comp in enumerate(competency_list):
                    default = 1 if preds[i] else 0
                    with (c1 if i % 2 == 0 else c2):
                        grade = st.radio(comp, [0, 1, 2, 3], index=default,
                                         horizontal=True, key=f"grade_{i}")
                        user_grades.append(grade)
                st.session_state.user_grades = user_grades
                st.success("‚úÖ –ì—Ä–µ–π–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

                # –ö–Ω–æ–ø–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞—è–≤–∫–∏
                if not st.session_state.get("submitted"):
                    if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞—è–≤–∫—É"):
                        try:
                            rec_id = save_application_to_db()
                        except psycopg2.errors.UniqueViolation as e:
                            cn = e.diag.constraint_name
                            if cn == "uq_resume_phone":
                                st.error("–ó–∞—è–≤–∫–∞ —Å —ç—Ç–∏–º –Ω–æ–º–µ—Ä–æ–º —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")
                            elif cn == "uq_resume_sender_email":
                                st.error("–ó–∞—è–≤–∫–∞ —Å —ç—Ç–∏–º email —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")
                            elif cn == "uq_resume_telegram_handle":
                                st.error("–ó–∞—è–≤–∫–∞ —Å —ç—Ç–∏–º Telegram-–Ω–∏–∫–Ω–µ–π–º–æ–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")
                            else:
                                st.error("–ó–∞—è–≤–∫–∞ —Å —Ç–∞–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
                            logging.warning("Duplicate application prevented", exc_info=True)
                        except Exception as e:
                            st.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞—è–≤–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
                            logging.error("Error saving application", exc_info=True)
                        else:
                            # –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–∏—Å—å–º–æ –∏ —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            sent = send_confirmation_email(
                                st.session_state.email,
                                rec_id,
                                st.session_state.name,
                                st.session_state.selected_professions
                            )
                            if sent:
                                st.success(
                                    f"‚úÖ –í–∞—à–∞ –∑–∞—è–≤–∫–∞ ‚Ññ{rec_id} –ø—Ä–∏–Ω—è—Ç–∞! "
                                    f"–ü–∏—Å—å–º–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ {st.session_state.email}"
                                )
                                st.session_state.submitted = True
                            # –µ—Å–ª–∏ sent == False, —Ç–æ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —É–∂–µ –≤—ã–≤–µ–ª–∏ st.error, —Ñ–ª–∞–≥ submitted –Ω–µ —Å—Ç–∞–≤–∏–º
                else:
                    st.info("–í—ã —É–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –∑–∞—è–≤–∫—É.")

        finally:
            try:
                os.remove(tmp_path)
            except OSError:
                pass

# ‚îÄ‚îÄ‚îÄ –ü–æ—Ç–æ–∫ HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
elif st.session_state.role == "hr":
    # 1. –§–ª–∞–≥ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if "hr_authenticated" not in st.session_state:
        st.session_state.hr_authenticated = False

    # 2. –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
    if not st.session_state.hr_authenticated:
        st.title("–í—Ö–æ–¥ –¥–ª—è HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞")
        pwd = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
        if st.button("–í–æ–π—Ç–∏"):
            if pwd == "duduki":
                st.session_state.hr_authenticated = True
            else:
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
        st.stop()

    # 3. –ì–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ HR
    st.title("–ü–∞–Ω–µ–ª—å HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞")

    # 5 –≤–∫–ª–∞–¥–æ–∫: 4√ó–ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ + –û–±—â–∞—è —Å–≤–æ–¥–∫–∞
    tab_labels = profession_names + ["–û–±—â–∞—è —Å–≤–æ–¥–∫–∞"]
    tabs = st.tabs(tab_labels)

    # –ú–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –Ω–∞ —Å—Ç–æ–ª–±–µ—Ü score
    score_mapping = {
        "–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö":           "datan_score",
        "–ú–µ–Ω–µ–¥–∂–µ—Ä –≤ –ò–ò":             "ai_manager_score",
        "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤ –ò–ò": "techan_score",
        "–ò–Ω–∂–µ–Ω–µ—Ä –¥–∞–Ω–Ω—ã—Ö":            "daten_score",
    }

    for idx, prof in enumerate(profession_names):
        with tabs[idx]:
            st.subheader(f"–í–∞–∫–∞–Ω—Å–∏—è: {prof}")

            # ‚Äî‚Äî –§–∏–ª—å—Ç—Ä—ã ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
            with st.expander("üîç –§–∏–ª—å—Ç—Ä—ã", expanded=True):
                # –î–∞—Ç—ã
                date_range = st.date_input(
                    "–ü–µ—Ä–∏–æ–¥ –∑–∞—è–≤–æ–∫",
                    value=(
                        datetime.date.today() - datetime.timedelta(days=30),
                        datetime.date.today()
                    ),
                    key=f"filter_date_{idx}"
                )
                # HR-email
                hr_emails = st.multiselect(
                    "HR Email",
                    options=[],
                    key=f"filter_hr_{idx}"
                )
                # GitHub
                git_choice = st.selectbox(
                    "GitHub",
                    ["–õ—é–±–æ–π", "–î–∞", "–ù–µ—Ç"],
                    key=f"filter_git_{idx}"
                )
                # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ø–æ –≥—Ä–µ–π–¥–∞–º
                st.markdown("**–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ø–æ –≥—Ä–µ–π–¥–∞–º**")
                req1 = st.multiselect(
                    "–ì—Ä–µ–π–¥ 1",
                    options=competency_list,
                    key=f"req1_{idx}"
                )
                req2 = st.multiselect(
                    "–ì—Ä–µ–π–¥ 2",
                    options=[c for c in competency_list if c not in req1],
                    key=f"req2_{idx}"
                )
                req3 = st.multiselect(
                    "–ì—Ä–µ–π–¥ 3",
                    options=[c for c in competency_list if c not in req1 + req2],
                    key=f"req3_{idx}"
                )
                # –í—Ç–æ—Ä–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è
                other_profs = ["–ù–µ –≤–∞–∂–Ω–æ"] + [p for p in profession_names if p != prof]
                sec_prof = st.selectbox(
                    "–ï—â—ë –æ–¥–Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è",
                    other_profs,
                    key=f"filter_secprof_{idx}"
                )
                # –î–∏–∞–ø–∞–∑–æ–Ω % —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
                col1, col2 = st.columns(2)
                min_score = col1.number_input(
                    "% –æ—Ç", min_value=0.0, max_value=100.0, value=0.0, step=0.1,
                    key=f"min_score_{idx}"
                )
                max_score = col2.number_input(
                    "% –¥–æ", min_value=0.0, max_value=100.0, value=100.0, step=0.1,
                    key=f"max_score_{idx}"
                )
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ score
                sort_asc = st.radio(
                    "–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ % —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è",
                    ["–ü–æ —É–±—ã–≤–∞–Ω–∏—é", "–ü–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"],
                    index=0,
                    key=f"filter_sort_{idx}"
                )

            # ‚Äî‚Äî –ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
            score_col = score_mapping[prof]
            conditions = ["%s = ANY(selected_professions)"]
            params = [prof]

            start_date, end_date = date_range
            conditions.append("uploaded_at::date BETWEEN %s AND %s")
            params += [start_date, end_date]
            if hr_emails:
                conditions.append("hr_email = ANY(%s)")
                params.append(hr_emails)
            if git_choice != "–õ—é–±–æ–π":
                conditions.append("git_available = %s")
                params.append(git_choice == "–î–∞")
            for comp in req1:
                conditions.append("%s = ANY(grade1)")
                params.append(comp)
            for comp in req2:
                conditions.append("%s = ANY(grade2)")
                params.append(comp)
            for comp in req3:
                conditions.append("%s = ANY(grade3)")
                params.append(comp)
            if sec_prof != "–ù–µ –≤–∞–∂–Ω–æ":
                conditions.append("%s = ANY(selected_professions)")
                params.append(sec_prof)
            conditions.append(f"{score_col} BETWEEN %s AND %s")
            params += [min_score, max_score]
            where_clause = " AND ".join(conditions)

            sql = f"""
                SELECT
                    id,
                    form_submitted_at,
                    uploaded_at,
                    sender_email,
                    name,
                    surname,
                    patronymic,
                    telegram_handle,
                    phone,
                    {score_col} AS score,
                    git_available,
                    selected_professions,
                    code,
                    hr_email,
                    grade0,
                    grade1,
                    grade2,
                    grade3,
                    original_filename
                FROM resume_records
                WHERE {where_clause};
            """
            conn = psycopg2.connect(host="localhost", dbname="resumes", user="appuser", password="duduki")
            df = pd.read_sql(sql, conn, params=params, parse_dates=["uploaded_at"]
            )
            conn.close()

            ascending = (sort_asc == "–ü–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é")
            df = df.sort_values("score", ascending=ascending).reset_index(drop=True)

            # ‚Äî‚Äî –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Ä–∞—Å—Å—ã–ª–∫–∞ ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
            filter_key = f"filter_passed_{idx}"
            if filter_key not in st.session_state:
                st.session_state[filter_key] = False
            col_thr, col_filter, col_send = st.columns([2,1,1])
            with col_thr:
                bulk_threshold = st.number_input(
                    "–ü–æ—Ä–æ–≥ % –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π —Ä–∞—Å—Å—ã–ª–∫–∏", min_value=0.0, max_value=100.0,
                    value=50.0, step=0.1, key=f"bulk_thr_{idx}"
                )
            with col_filter:
                if st.button("–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ—à–µ–¥—à–∏—Ö", key=f"filter_btn_{idx}"):
                    st.session_state[filter_key] = True
            with col_send:
                bulk_send = st.button(f"üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–∏—Å—å–º–∞ –¥–ª—è ¬´{prof}¬ª", key=f"bulk_send_{idx}")

            if st.session_state[filter_key]:
                st.subheader(f"–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º ‚â• {bulk_threshold}%")

                # 1) —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
                total   = len(df)
                passed  = len(df[df["score"] >= bulk_threshold])
                percent = (passed / total * 100) if total else 0.0
                c1, c2, c3 = st.columns(3)
                c1.metric("–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", total)
                c2.metric(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ‚â•{bulk_threshold}%", passed)
                c3.metric("–î–æ–ª—è –ø—Ä–æ—à–µ–¥—à–∏—Ö", f"{percent:.1f}%")
                st.caption("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É ¬´üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–∏—Å—å–º–∞¬ª, —á—Ç–æ–±—ã —Ä–∞–∑–æ—Å–ª–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º.")

                # 2) –∑–∞—Ç–µ–º —Å–∞–º–∞ —Ç–∞–±–ª–∏—Ü–∞
                df_passed = df[df["score"] >= bulk_threshold].reset_index(drop=True)
                st.dataframe(df_passed, use_container_width=True)

            st.subheader(f"–í—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏ ¬´{prof}¬ª")
            st.dataframe(df, use_container_width=True)

            if bulk_send:
                sent_A = sent_B = skipped = 0
                for _, row in df.iterrows():
                    above = row["score"] >= bulk_threshold
                    ok = send_bulk_mail(row, prof, bulk_threshold, above)
                    if ok:
                        sent_A += above
                        sent_B += (not above)
                    else:
                        skipped += 1
                st.success(
                    f"‚úÖ –ü–∏—Å—å–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã:\n"
                    f"  –ö–∞–Ω–¥–∏–¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –±–æ–ª—å—à–µ –ø–æ—Ä–æ–≥–∞ (‚â•{bulk_threshold}%): {sent_A}\n."
                    f"  –ö–∞–Ω–¥–∏–¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–µ–Ω—å—à–µ –ø–æ—Ä–æ–≥–∞ (<{bulk_threshold}%): {sent_B}\n."
                    f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö email: {skipped}.")

            st.markdown("### üìñ –û–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª–µ–π —Ç–∞–±–ª–∏—Ü—ã")
            descriptions = {
                "id":                   "–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞—è–≤–∫–∏",
                "form_submitted_at":    "–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "uploaded_at":          "–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—é–º–µ",
                "sender_email":         "Email –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "name":                 "–ò–º—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "surname":              "–§–∞–º–∏–ª–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "patronymic":           "–û—Ç—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "telegram_handle":      "Telegram-–Ω–∏–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
                "phone":                "–¢–µ–ª–µ—Ñ–æ–Ω –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (+7XXXXXXXXXX)",
                "score":                f"–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–æ—Ñ–∏–ª—é ¬´{prof}¬ª",
                "git_available":        "–ù–∞–ª–∏—á–∏–µ GitHub-—Å—Å—ã–ª–∫–∏",
                "selected_professions": "–ü—Ä–æ—Ñ–µ—Å—Å–∏–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º",
                "code":                 "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ–¥ –∑–∞—è–≤–∫–∏",
                "hr_email":             "Email HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞, –ø—Ä–∏–Ω—è–≤—à–µ–≥–æ –∑–∞—è–≤–∫—É",
                "grade0":               "–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ —Å –≥—Ä–µ–π–¥–æ–º 0",
                "grade1":               "–ì—Ä–µ–π–¥—ã 1",
                "grade2":               "–ì—Ä–µ–π–¥—ã 2",
                "grade3":               "–ì—Ä–µ–π–¥—ã 3",
                "original_filename":    "–ò–º—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Ä–µ–∑—é–º–µ"
            }
            items = list(descriptions.items())
            half = (len(items) + 1) // 2
            col1, col2 = st.columns(2)
            for key, txt in items[:half]: col1.markdown(f"**{key}** ‚Äî {txt}")
            for key, txt in items[half:]: col2.markdown(f"**{key}** ‚Äî {txt}")

# ‚îÄ‚îÄ‚îÄ –ü—è—Ç–∞—è –≤–∫–ª–∞–¥–∫–∞ ‚Äî –æ–±—â–∏–π –¥–∞—à–±–æ—Ä–¥ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    with tabs[-1]:
        st.subheader("–û–±—â–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º")

        # 1. –ó–∞–≥—Ä—É–∑–∏–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
        conn = psycopg2.connect(host="localhost", dbname="resumes", user="appuser", password="duduki")
        df_all = pd.read_sql(
            "SELECT * FROM resume_records",
            conn,
            parse_dates=["uploaded_at", "form_submitted_at"]
        )
        conn.close()

        # 2. –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        total_apps     = len(df_all)
        avg_all_scores = round(np.mean([df_all[col].mean() for col in score_mapping.values()]), 1)
        apps_last_7d   = int(df_all.set_index("form_submitted_at").last("7D").shape[0])
        git_share      = f"{round(df_all['git_available'].mean()*100, 1)}%"
        hr_count       = df_all['hr_email'].nunique()
        avg_delay_mins = round(((df_all['uploaded_at'] - df_all['form_submitted_at'])
                                .dt.total_seconds() / 60).mean(), 1)

        # 3. –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ —Å–≤–µ—Ä—Ö—É (—à—Ä–∏—Ñ—Ç –º–æ–∂–Ω–æ –∫–∞—Å—Ç–æ–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ st.markdown + HTML/CSS)
        m1, m2, m3, m4, m5, m6 = st.columns(6)
        m1.metric("–í—Å–µ–≥–æ –∑–∞—è–≤–æ–∫",          f"{total_apps}",      help="–í—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∑–∞—è–≤–∫–∏")
        m2.metric("–°—Ä–µ–¥–Ω–∏–π % –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º", f"{avg_all_scores}%", help="–°—Ä–µ–¥–Ω–µ–µ –∏–∑ –≤—Å–µ—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π")
        m3.metric("–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω.",    f"{apps_last_7d}",    help="–ó–∞—è–≤–∫–∏ –∑–∞ –Ω–µ–¥–µ–ª—é")
        m4.metric("–î–æ–ª—è —Å GitHub",         git_share,            help="–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å GitHub")
        m5.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö HR",         f"{hr_count}",        help="–ß–∏—Å–ª–æ HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤")
        m6.metric("–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞",      f"{avg_delay_mins} –º–∏–Ω", help="–ú–∏–Ω—É—Ç—ã –º–µ–∂–¥—É —Ñ–æ—Ä–º–æ–π –∏ –∑–∞–≥—Ä—É–∑–∫–æ–π")

        # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        prof_counts      = df_all.explode("selected_professions")["selected_professions"] \
                                .value_counts().reindex(profession_names, fill_value=0)
        avg_scores       = pd.Series({prof: df_all[col].mean() for prof, col in score_mapping.items()}) \
                            .reindex(profession_names)
        timeseries       = df_all.set_index("form_submitted_at").resample("D").size()
        avg_per_candidate= df_all[list(score_mapping.values())].mean(axis=1)
        all_grades       = pd.concat([df_all[f"grade{i}"].explode() for i in range(4)], ignore_index=True).dropna()
        top10_comps      = all_grades.value_counts().head(10)

        # 5. –¶–≤–µ—Ç–æ–≤—ã–µ –ø–∞–ª–∏—Ç—Ä—ã
        cmap_prof = cm.get_cmap("tab10", len(profession_names))
        colors_prof = {prof: cmap_prof(i) for i, prof in enumerate(profession_names)}
        cmap_comp = cm.get_cmap("tab20", len(top10_comps))
        colors_comp = {comp: cmap_comp(i) for i, comp in enumerate(top10_comps.index)}

        # 6. –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞—à–±–æ—Ä–¥–∞ 2√ó2 + –æ–¥–∏–Ω —Å–Ω–∏–∑—É
        r1c1, r1c2 = st.columns(2)
        with r1c1:
            st.markdown("### –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –ø–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º")
            fig1, ax1 = plt.subplots(figsize=(4, 3), constrained_layout=True)  # –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å figsize
            xs, ys = prof_counts.index, prof_counts.values
            ax1.bar(xs, ys, color=[colors_prof[x] for x in xs])
            ax1.set_ylabel("–ß–∏—Å–ª–æ –∑–∞—è–≤–æ–∫")
            ax1.tick_params(axis="x", rotation=45)
            st.pyplot(fig1)

        with r1c2:
            st.markdown("### –°—Ä–µ–¥–Ω–∏–π % —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º")
            fig2, ax2 = plt.subplots(figsize=(4, 3), constrained_layout=True)
            xs2, ys2 = avg_scores.index, avg_scores.values
            ax2.barh(xs2, ys2, color=[colors_prof[x] for x in xs2])
            ax2.set_xlabel("–°—Ä–µ–¥–Ω–∏–π %")
            st.pyplot(fig2)

        r2c1, r2c2 = st.columns(2)
        with r2c1:
            st.markdown("### –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –∑–∞—è–≤–æ–∫")
            fig3, ax3 = plt.subplots(figsize=(4, 3), constrained_layout=True)
            ax3.plot(timeseries.index, timeseries.values, marker="o")
            ax3.set_xlabel("–î–∞—Ç–∞")
            ax3.set_ylabel("–ß–∏—Å–ª–æ –∑–∞—è–≤–æ–∫")
            ax3.tick_params(axis="x", rotation=45)
            st.pyplot(fig3)

        with r2c2:
            st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ % —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è")
            fig4, ax4 = plt.subplots(figsize=(4, 3), constrained_layout=True)
            ax4.hist(avg_per_candidate, bins=20, color="#4c72b0")
            ax4.set_xlabel("–°—Ä–µ–¥–Ω–∏–π %")
            ax4.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
            st.pyplot(fig4)

        # ‚îÄ‚îÄ‚îÄ –¢–æ–ø‚Äë5 –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –ø–æ –≥—Ä–µ–π–¥–∞–º ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ø‚Äë5 –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥—Ä–µ–π–¥–∞
        top5 = {
            i: df_all[f"grade{i}"].explode().value_counts().head(5)
            for i in range(4)
        }

        st.markdown("## –¢–æ–ø‚Äë5 –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –ø–æ –≥—Ä–µ–π–¥–∞–º")
        for i in range(4):
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Series –≤ DataFrame
            df_top = top5[i].rename_axis("–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è").reset_index(name="–ß–∞—Å—Ç–æ—Ç–∞")
    
            st.subheader(f"–ì—Ä–µ–π–¥ {i}")
            # –¢–∞–±–ª–∏—Ü–∞ —Å —Ü–∏—Ñ—Ä–∞–º–∏
            st.table(df_top)
            # –ò –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π bar‚Äëchart
            st.bar_chart(
                df_top.set_index("–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è")["–ß–∞—Å—Ç–æ—Ç–∞"],
                use_container_width=True
            )