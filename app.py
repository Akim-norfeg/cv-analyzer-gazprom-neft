import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from huggingface_hub import login
import torch
import numpy as np
import os

from utils.cv_reader import read_resume_from_file
from utils.github_reader import extract_github_links_from_text, collect_github_text
from utils.resume_processor import preprocess_text
from utils.constants import competency_list, profession_matrix, profession_names

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="AI –†–µ–∑—é–º–µ –ê–Ω–∞–ª–∏–∑", layout="wide")
st.title("üíº AI –ê–Ω–∞–ª–∏–∑ –†–µ–∑—é–º–µ –∏ –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∏–≤–∞—Ç–Ω–æ–≥–æ Hugging Face Hub
@st.cache_resource
def load_model():
    login(token=st.secrets["HUGGINGFACE_TOKEN"])  # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ç–æ–∫–µ–Ω
    repo_id = "KsyLight/resume-ai-competency-model"
    tokenizer = AutoTokenizer.from_pretrained(repo_id, use_auth_token=True)
    model = AutoModelForSequenceClassification.from_pretrained(repo_id, use_auth_token=True)
    model.eval()
    return tokenizer, model

tokenizer, model = load_model()

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def predict_competencies(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = torch.sigmoid(outputs.logits).squeeze().cpu().numpy()
    binary_preds = (probs > 0.5).astype(int)
    return binary_preds, probs

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ
uploaded_file = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–µ —Ä–µ–∑—é–º–µ (PDF, DOCX, TXT)", type=["pdf", "docx", "txt"])

if uploaded_file:
    with st.spinner("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞..."):
        with open("temp_file", "wb") as f:
            f.write(uploaded_file.read())

        base_text = read_resume_from_file("temp_file")
        gh_links = extract_github_links_from_text(base_text)
        github_text = " ".join([collect_github_text(link) for link in gh_links]) if gh_links else ""
        full_text = preprocess_text(base_text + " " + github_text)

    with st.spinner("ü§ñ –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω–∞–ª–∏–∑..."):
        pred_vector, prob_vector = predict_competencies(full_text)

    # –í—ã–≤–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
    st.subheader("üß† –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:")
    for i, prob in enumerate(prob_vector):
        if pred_vector[i] == 1:
            comp = competency_list[i]
            st.markdown(f"- ‚úÖ {comp} ‚Äî **{prob:.2f}**")

    # –ì—Ä–µ–π–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.markdown("---")
    st.subheader("üìà –£–∫–∞–∂–∏—Ç–µ —Å–≤–æ–π –≥—Ä–µ–π–¥ (0‚Äì3) –ø–æ –∫–∞–∂–¥–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏:")

    user_grades = []
    for i, comp in enumerate(competency_list):
        default = 1 if pred_vector[i] == 1 else 0
        grade = st.selectbox(f"{comp}", options=[0, 1, 2, 3], index=default, key=f"grade_{i}")
        user_grades.append(grade)

    # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º
    st.markdown("---")
    st.subheader("üß© –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º:")

    user_vector = np.array(user_grades)
    for prof_idx, prof_name in enumerate(profession_names):
        prof_required = profession_matrix[:, prof_idx]
        total_required = np.sum(prof_required > 0)
        matched = np.sum((user_vector >= prof_required) & (prof_required > 0))
        percent = (matched / total_required) * 100 if total_required > 0 else 0
        st.write(f"üîπ **{prof_name}**: {percent:.1f}% —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è")

    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –±—É–¥—É—â–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    st.markdown("---")
    st.subheader("üîÆ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ –ø–æ–∑–∂–µ)")
    st.info("–ó–¥–µ—Å—å –ø–æ—è–≤—è—Ç—Å—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ä—å–µ—Ä–Ω—ã–º —Ç—Ä–µ–∫–∞–º –∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–º –≤–∞–∫–∞–Ω—Å–∏—è–º.")

    # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ
    with st.expander("üßæ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ"):
        st.text(full_text)

    os.remove("temp_file")